> This isn't meant as a resume. It illustrates the university's lack of standing as a credible institution, having opposed and been late to every idea that turned out to be the next major leap in the field, including some I don't have the energy to elaborate on.
>
> It mainly shows how much I did in the first 3 years, amid the extreme terror, tragedy, and obstruction with the same institution on me concurrently. See [here](https://github.com/slerman12/Detective-Sam/blob/main/6-Indebted.md) for work I did throughout my PhD.
> 
> I under-stress how much they argued, pre-emptively judged, and disagreed.

“A ChatGPT paper” refers to a work I did in 2018 when I was studying RL, called [“Distributional Relations In Deep Learning.”](https://www.overleaf.com/read/qgmmzgsrctmg#6cd1b9) Back then, the professors at the University of Rochester in majority believed and argued that Deep Learning was a fad. My first advisor, Henry Kautz, was somewhat better but really skeptical of my obsession with this obscure thing called “MHDPA”, the method behind ChatGPT and is now central to deep learning, you can't get away with not hearing about it. He emailed that he thought I should focus on Neural Architecture Search. I was (somewhat heretically) interested in reinforcement learning, relational reasoning (such as via MHDPA, both for sequences and spatial entities / vision, but note that back then this was an alienating and argued-against view to take), and long-term lifelong memory (such as the early neural episodic control and memory networks). At the time of that work, I was probably the only one outside of DeepMind who heard of MHDPA and certainly at my university. An author of an MHDPA-based RNN at NeurIPS 2018 was so impressed with me he even said he’d recommend me to his colleagues at DeepMind if I applied, though I of course never did because I was hospitalized and brain damaged around that time. By the way, I finished running the experiements for that paper literally in the hospital. My mom had to bring in my laptop. Henry once told me, "Ideas are cheap. Execution is hard." I did both and never got credit.
 
Back then I had to use Tensorflow 1.0 and there wasn’t an existing infrastructure. I ran the experiments I could in the hospital and got successful results. The reviewers of the paper who rejected it didn’t know what MHDPA was. And they were unsatisfied with the number of experiments, and the jargon about relational reasoning (today, "relational reasoning" is convention). That work and foresight, much like muuuch and maaany of the disciplines and work of my doctoral-program years (and this really can’t be understated), got wasted, often by ill-timed sudden and improbable circumstances, including foolish advisors and environment. 

Then both the induced brain damage happened and I had to find a new advisor, while clocking in simultaneously at the Medical Center for funding where I built a prognostication web app and a pipeline for disease prognostication. Then Covid, just as I was starting to recover from the emotional impact of induced hair loss and >year induced benzodiazepine Hellish torment (and actual brain damage).

#

> **Most recently**, my second advisor decided last-minute out of nowhere in the middle of a paper review (of a paper that had positive reviews and got accepted) that I didn’t have enough papers. And I was terminated before being able to run my robotics / foundation model experiments on the A6000s, literally a week after having finished the core programming for them. [I released that code open source](https://github.com/AGI-init/tributaries/blob/main/Examples/Sweeps/Bittle.py), but have no funding and barely the morale left to finalize, as this passion, work, and open-source generosity, is again wasted.

#

Note: I was new to Deep Learning in 2017 when I entered the program. I learned it fast while balancing the extremely-myopic “breadth” courses I had to take. I graduated my undergrad (with two degrees in Comp Sci and Math) in May, 2017 and went straight into the PhD program in September with the idea of studying empathy and giving empathy to machines ([it’s not as stupid as it sounds](https://github.com/slerman12/PersonalWebpage/blob/master/IRTG%20Project%20Proposal.pdf)). Then I started Transcendental Meditation and had hypnogogic revelations about ontological entities composing relations querying associative memories, a method of nearest neighbors long-term memory I envisioned in a hypnogogic state that I called “circle waves” that DeepMind turned out to have a similar line on with Neural Episodic Control, but to be clear: I arived to it before that paper, and as for "hypnogogic", I always remained lucid and professional.

I should add: I got an [honorable mention](https://www.research.gov/grfp/AwardeeList.do?method=loadAwardeeList) (type in Samuel Lerman under "Search by Name" and select "All Years") in the NSF GRFP, with all excellent reviews and the only doubt being that (at the time) I didn't have any publications. That is a highly competitive fellowship, but I received no funding due to that reason. Oh, the excellent reviews were for that very idea (composing relations querying associative memories) that I just qualified with an unnecessary disclaimer about acting professional, because despite the passion with which I considered these ideas (even entering "hypnogogic states"), I always acted professionally. This was my area exam, 2nd year as PhD student in program: [here](https://docs.google.com/presentation/d/1LK0urIs8yu_e7HyZ-VQoDJUiGpPeTPEUgfhjK5Kw_7w/edit?usp=sharing). Deep learning professor Chenliang Xu, at that area exam, asked me how I planned to do "relational representations", and I turned to slide 11, and taught them MHDPA. My then-advisor Henry Kautz didn't like that I called it "relational reasoning", but that is now a convention. In his defense, he told me I "passed with flying colors." To be fair to Chenliang, the advisor who decided I didn't have enough papers when he decided to leave (when I published 2 in the 3 years under him), it was and still is impressive to me that of all of them he was the only one who inquired on *how* I planned to do relational representations. MHDPA is the method that today underpins large-language models like ChatGPT, and ViTs. See [here](https://github.com/slerman12/Detective-Sam/blob/Ancillary/Conv-is-all-you-need.md) for an innovative explanation of them that I called "Conv is all you need", also teaching a little more than the succinctness would let on.

> I also proposed these [bio-inspired neurons]( https://drive.google.com/file/d/1i5hS2iDVuo24PnGicvn5dIZYXUzDfPAl/view?usp=share_link) to my semantic parsing class in 2018, to Henry, and again to Chenliang later. But, no one other than me particularly took an interest, despite the extremely original, intuitive understanding.
